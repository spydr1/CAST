{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import research.slim.nets.mobilenet.conv_blocks as ops\n",
    "from research.slim.nets.mobilenet import mobilenet as lib\n",
    "expand_input = ops.expand_input_by_factor\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import slim\n",
    "from research.slim.nets.mobilenet import mobilenet_v2\n",
    "\n",
    "import contextlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_training = False\n",
    "weight_decay = 1e-5 \n",
    "expand_kwargs = {\n",
    "    'expansion_size': expand_input(6),       \n",
    "    'split_expansion': 1,\n",
    "    'normalizer_fn': slim.batch_norm,\n",
    "    'residual': True\n",
    "}\n",
    "with tf.variable_scope('decoder') :\n",
    "    batch_norm_params = {'center': True, 'scale': True,'is_training': is_training}\n",
    "    with slim.arg_scope([slim.conv2d, slim.fully_connected, slim.separable_conv2d],\n",
    "                                activation_fn=tf.nn.relu6,\n",
    "                                normalizer_fn=slim.batch_norm,\n",
    "                                normalizer_params=batch_norm_params,\n",
    "                                weights_regularizer=slim.l2_regularizer(weight_decay)):\n",
    "        with slim.arg_scope([ops.expanded_conv],**expand_kwargs):\n",
    "            with slim.arg_scope([slim.conv2d, slim.separable_conv2d],padding='SAME'):\n",
    "                conv = ops.expanded_conv(input_images,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "Variables: name (type shape) [size]\n",
      "---------\n",
      "feature_fusion/expanded_conv/expand/weights:0 (float32_ref 1x1x3x24) [72, bytes: 288]\n",
      "feature_fusion/expanded_conv/expand/BatchNorm/gamma:0 (float32_ref 24) [24, bytes: 96]\n",
      "feature_fusion/expanded_conv/expand/BatchNorm/beta:0 (float32_ref 24) [24, bytes: 96]\n",
      "feature_fusion/expanded_conv/expand/BatchNorm/moving_mean:0 (float32_ref 24) [24, bytes: 96]\n",
      "feature_fusion/expanded_conv/expand/BatchNorm/moving_variance:0 (float32_ref 24) [24, bytes: 96]\n",
      "feature_fusion/expanded_conv/depthwise/depthwise_weights:0 (float32_ref 3x3x24x1) [216, bytes: 864]\n",
      "feature_fusion/expanded_conv/depthwise/BatchNorm/gamma:0 (float32_ref 24) [24, bytes: 96]\n",
      "feature_fusion/expanded_conv/depthwise/BatchNorm/beta:0 (float32_ref 24) [24, bytes: 96]\n",
      "feature_fusion/expanded_conv/depthwise/BatchNorm/moving_mean:0 (float32_ref 24) [24, bytes: 96]\n",
      "feature_fusion/expanded_conv/depthwise/BatchNorm/moving_variance:0 (float32_ref 24) [24, bytes: 96]\n",
      "feature_fusion/expanded_conv/project/weights:0 (float32_ref 1x1x24x256) [6144, bytes: 24576]\n",
      "feature_fusion/expanded_conv/project/BatchNorm/gamma:0 (float32_ref 256) [256, bytes: 1024]\n",
      "feature_fusion/expanded_conv/project/BatchNorm/beta:0 (float32_ref 256) [256, bytes: 1024]\n",
      "feature_fusion/expanded_conv/project/BatchNorm/moving_mean:0 (float32_ref 256) [256, bytes: 1024]\n",
      "feature_fusion/expanded_conv/project/BatchNorm/moving_variance:0 (float32_ref 256) [256, bytes: 1024]\n",
      "Total size of variables: 7648\n",
      "Total bytes of variables: 30592\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7648, 30592)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "slim.model_analyzer.analyze_vars(tf.global_variables(), print_info=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expand_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_images = tf.placeholder(tf.float32, shape=[None, None, None, 3], name='input_images')\n",
    "\n",
    "with slim.arg_scope(mobilenet_v2.training_scope(weight_decay=1e-4)):\n",
    "    logits, endpoints = mobilenet_v2.mobilenet_base(input_images,is_training=False)\n",
    "    \n",
    "slim.model_analyzer.analyze_vars(tf.global_variables(), print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in tf.global_variables():\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.get_collection(tf.Graph\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.Graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
