{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "from research.slim.nets.mobilenet import mobilenet_v2\n",
    "\n",
    "from tensorflow.contrib import slim\n",
    "import research.slim.nets.mobilenet.conv_blocks as ops\n",
    "from research.slim.nets.mobilenet import mobilenet as lib\n",
    "expand_input = ops.expand_input_by_factor\n",
    "from Analysis.count_flops import count \n",
    "import os \n",
    "\n",
    "# Define a scenario\n",
    "batch_size = 8\n",
    "channels = 32\n",
    "image_size = 16\n",
    "feature_maps = 64\n",
    "filter_size = 512\n",
    "depthwise_filters = 8\n",
    "tf.reset_default_graph()\n",
    "# Dummy images\n",
    "images = tf.random_normal(shape=[batch_size,image_size, image_size,3], \n",
    "                          dtype=tf.float32)\n",
    "normal = slim.conv2d(images,128,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "\n",
    "normal = slim.conv2d(normal,64,3,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "#normal = slim.conv2d(normal,1,1)\n",
    "\n",
    "\n",
    "# Separable method\n",
    "separable = ops.expanded_conv(images,32,expansion_size= expand_input(6,divisible_by=1),residual=False)\n",
    "separable = ops.expanded_conv(separable,32,expansion_size= expand_input(6,divisible_by=1),residual=False)\n",
    "separable = ops.expanded_conv(separable,32,expansion_size= expand_input(6,divisible_by=1),residual=False)\n",
    "separable = ops.expanded_conv(separable,32,expansion_size= expand_input(6,divisible_by=1),residual=False)\n",
    "separable = ops.expanded_conv(separable,32,expansion_size= expand_input(6,divisible_by=1),residual=False)\n",
    "\n",
    "separable = ops.expanded_conv(separable,32,expansion_size= expand_input(6,divisible_by=1),residual=False)\n",
    "\n",
    "\n",
    "point = slim.conv2d(images,128,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point = slim.conv2d(point,128,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point = slim.conv2d(point,128,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point = slim.conv2d(point,128,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point = slim.conv2d(point,128,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point = slim.conv2d(point,128,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "\n",
    "\n",
    "#separable = slim.conv2d(separable,1,1)\n",
    "\n",
    "\n",
    "\n",
    "config = tf.ConfigProto(device_count = {'GPU': 1})\n",
    "with tf.Session(config=config) as sess:\n",
    "\n",
    "    # Assert equality of the different methods\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    norm, sep = sess.run([normal, separable])\n",
    "    #np.testing.assert_almost_equal(norm, sep, decimal=3)\n",
    "\n",
    "    repeats = 256\n",
    "\n",
    "    # Benchmark normal method\n",
    "    start = time.time()\n",
    "    for _ in range(repeats):\n",
    "        _ = sess.run(normal)\n",
    "    end = time.time()\n",
    "    d1 = (end - start) / repeats * 100\n",
    "\n",
    "    # Benchmark seperable method\n",
    "    start = time.time()\n",
    "    for _ in range(repeats):\n",
    "        _ = sess.run(separable)\n",
    "    end = time.time()\n",
    "    d3 = (end - start) / repeats * 100\n",
    "    \n",
    "    start = time.time()\n",
    "    for _ in range(repeats):\n",
    "        _ = sess.run(point)\n",
    "    end = time.time()\n",
    "    d2 = (end - start) / repeats * 100\n",
    "\n",
    "\n",
    "    # Print results\n",
    "    print(\"conv\",count(tf.get_default_graph() ,[normal.op.name]))\n",
    "    print(\"point\",count(tf.get_default_graph() ,[point.op.name]))\n",
    "    print(\"sep\",count(tf.get_default_graph() ,[separable.op.name]))\n",
    "\n",
    "    print(\"Normal method: {}ms \\t PointWise: {}ms Separable method: {}ms\".format(d1,d2, d3))\n",
    "\n",
    "config = tf.ConfigProto(device_count = {'GPU': 0})\n",
    "with tf.Session(config=config) as sess:\n",
    "\n",
    "    # Assert equality of the different methods\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    norm, sep = sess.run([normal, separable])\n",
    "    #np.testing.assert_almost_equal(norm, sep, decimal=3)\n",
    "\n",
    "    repeats = 256\n",
    "\n",
    "    # Benchmark normal method\n",
    "    start = time.time()\n",
    "    for _ in range(repeats):\n",
    "        _ = sess.run(normal)\n",
    "    end = time.time()\n",
    "    d1 = (end - start) / repeats * 100\n",
    "\n",
    "    # Benchmark seperable method\n",
    "    start = time.time()\n",
    "    for _ in range(repeats):\n",
    "        _ = sess.run(separable)\n",
    "    end = time.time()\n",
    "    d3 = (end - start) / repeats * 100\n",
    "    \n",
    "    start = time.time()\n",
    "    for _ in range(repeats):\n",
    "        _ = sess.run(point)\n",
    "    end = time.time()\n",
    "    d2 = (end - start) / repeats * 100\n",
    "\n",
    "\n",
    "    # Print results\n",
    "    print(\"conv\",count(tf.get_default_graph() ,[normal.op.name]))\n",
    "    print(\"point\",count(tf.get_default_graph() ,[point.op.name]))\n",
    "    print(\"sep\",count(tf.get_default_graph() ,[separable.op.name]))\n",
    "\n",
    "\n",
    "    print(\"Normal method: {}ms \\t PointWise: {}ms Separable method: {}ms\".format(d1,d2, d3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from tensorflow.contrib import slim\n",
    "import sys \n",
    "sys.path.append('./Analysis/')\n",
    "from count_flops import count \n",
    "import os \n",
    "\n",
    "# Define a scenario\n",
    "batch_size = 4\n",
    "channels = 32\n",
    "image_size = 128\n",
    "feature_maps = 64\n",
    "filter_size = 512\n",
    "depthwise_filters = 8\n",
    "tf.reset_default_graph()\n",
    "# Dummy images\n",
    "images = tf.random_normal(shape=[batch_size,image_size, image_size,3], \n",
    "                          dtype=tf.float32)\n",
    "normal = slim.conv2d(images,64,3,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "\n",
    "normal = slim.conv2d(normal,128,3,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "#normal = slim.conv2d(normal,1,1)\n",
    "\n",
    "point = slim.conv2d(images,128,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point = slim.conv2d(point,128,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point = slim.conv2d(point,128,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point = slim.conv2d(point,128,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point = slim.conv2d(point,128,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point = slim.conv2d(point,64,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "\n",
    "\n",
    "#separable = slim.conv2d(separable,1,1)\n",
    "\n",
    "point2 = slim.conv2d(images,256,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point2 = slim.conv2d(point2,256,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "\n",
    "point3 = slim.conv2d(images,64,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point3 = slim.conv2d(point3,64,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point3 = slim.conv2d(point3,64,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point3 = slim.conv2d(point3,64,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point3 = slim.conv2d(point3,64,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point3 = slim.conv2d(point3,64,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point3 = slim.conv2d(point3,64,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point3 = slim.conv2d(point3,64,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point3 = slim.conv2d(point3,64,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point3 = slim.conv2d(point3,64,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point3 = slim.conv2d(point3,64,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point3 = slim.conv2d(point3,64,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point3 = slim.conv2d(point3,64,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point3 = slim.conv2d(point3,64,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point3 = slim.conv2d(point3,64,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point3 = slim.conv2d(point3,64,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point3 = slim.conv2d(point3,64,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point3 = slim.conv2d(point3,64,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point3 = slim.conv2d(point3,64,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "\n",
    "\n",
    "\n",
    "config = tf.ConfigProto(device_count = {'GPU': 0})\n",
    "with tf.Session(config=config) as sess:\n",
    "    # Assert equality of the different methods\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    check_time([normal,point,point2,point3])\n",
    "\n",
    "config = tf.ConfigProto(device_count = {'GPU': 1})\n",
    "with tf.Session(config=config) as sess:\n",
    "    # Assert equality of the different methods\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    check_time([normal,point,point2,point3])\n",
    "    \n",
    "# layer가 많으면 기본적으로 좀더 많은시간이 걸림 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from tensorflow.contrib import slim\n",
    "import sys \n",
    "sys.path.append('./Analysis/')\n",
    "from count_flops import count \n",
    "import os \n",
    "\n",
    "# Define a scenario\n",
    "batch_size = 4\n",
    "channels = 32\n",
    "image_size = 32\n",
    "feature_maps = 64\n",
    "filter_size = 512\n",
    "depthwise_filters = 8\n",
    "tf.reset_default_graph()\n",
    "# Dummy images\n",
    "images = tf.random_normal(shape=[batch_size,image_size, image_size,3], \n",
    "                          dtype=tf.float32)\n",
    "normal = slim.conv2d(images,64,3,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "\n",
    "normal = slim.conv2d(normal,128,3,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "#normal = slim.conv2d(normal,1,1)\n",
    "\n",
    "point = slim.conv2d(images,128,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point = slim.conv2d(point,128,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point = slim.conv2d(point,128,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point = slim.conv2d(point,128,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point = slim.conv2d(point,128,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point = slim.conv2d(point,64,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "\n",
    "\n",
    "#separable = slim.conv2d(separable,1,1)\n",
    "\n",
    "point2 = slim.conv2d(images,256,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point2 = slim.conv2d(point2,256,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "\n",
    "point3 = slim.conv2d(images,2,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point3 = slim.conv2d(point3,2,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point3 = slim.conv2d(point3,2,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point3 = slim.conv2d(point3,2,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point3 = slim.conv2d(point3,2,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point3 = slim.conv2d(point3,2,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point3 = slim.conv2d(point3,2,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point3 = slim.conv2d(point3,2,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point3 = slim.conv2d(point3,2,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point3 = slim.conv2d(point3,2,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "\n",
    "point3 = slim.conv2d(point3,2,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point3 = slim.conv2d(point3,2,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point3 = slim.conv2d(point3,2,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point3 = slim.conv2d(point3,2,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point3 = slim.conv2d(point3,2,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point3 = slim.conv2d(point3,2,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point3 = slim.conv2d(point3,2,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point3 = slim.conv2d(point3,2,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point3 = slim.conv2d(point3,2,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point3 = slim.conv2d(point3,2,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "\n",
    "point4 = slim.conv2d(images,2,1)\n",
    "point4 = slim.conv2d(point4,2,1)\n",
    "point4 = slim.conv2d(point4,2,1)\n",
    "point4 = slim.conv2d(point4,2,1)\n",
    "point4 = slim.conv2d(point4,2,1)\n",
    "point4 = slim.conv2d(point4,2,1)\n",
    "point4 = slim.conv2d(point4,2,1)\n",
    "point4 = slim.conv2d(point4,2,1)\n",
    "point4 = slim.conv2d(point4,2,1)\n",
    "point4 = slim.conv2d(point4,2,1)\n",
    "\n",
    "point4 = slim.conv2d(point4,2,1)\n",
    "point4 = slim.conv2d(point4,2,1)\n",
    "point4 = slim.conv2d(point4,2,1)\n",
    "point4 = slim.conv2d(point4,2,1)\n",
    "point4 = slim.conv2d(point4,2,1)\n",
    "point4 = slim.conv2d(point4,2,1)\n",
    "point4 = slim.conv2d(point4,2,1)\n",
    "point4 = slim.conv2d(point4,2,1)\n",
    "point4 = slim.conv2d(point4,2,1)\n",
    "point4 = slim.conv2d(point4,2,1)\n",
    "\n",
    "\n",
    "config = tf.ConfigProto(device_count = {'GPU': 1})\n",
    "with tf.Session(config=config) as sess:\n",
    "    # Assert equality of the different methods\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    check_time([normal,point,point2,point3,point4])\n",
    "\n",
    "# layer가 많으면 기본적으로 좀더 많은시간이 걸림 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "images = tf.random_normal(shape=[batch_size,image_size, image_size,3], \n",
    "                          dtype=tf.float32)\n",
    "point4 = slim.conv2d(images,2,1)\n",
    "point4 = slim.conv2d(point4,2,1)\n",
    "point4 = slim.conv2d(point4,2,1)\n",
    "point4 = slim.conv2d(point4,2,1)\n",
    "point4 = slim.conv2d(point4,2,1)\n",
    "point4 = slim.conv2d(point4,2,1)\n",
    "point4 = slim.conv2d(point4,2,1)\n",
    "point4 = slim.conv2d(point4,2,1)\n",
    "point4 = slim.conv2d(point4,2,1)\n",
    "point4 = slim.conv2d(point4,2,1)\n",
    "\n",
    "point4 = slim.conv2d(point4,2,1)\n",
    "point4 = slim.conv2d(point4,2,1)\n",
    "point4 = slim.conv2d(point4,2,1)\n",
    "point4 = slim.conv2d(point4,2,1)\n",
    "point4 = slim.conv2d(point4,2,1)\n",
    "point4 = slim.conv2d(point4,2,1)\n",
    "point4 = slim.conv2d(point4,2,1)\n",
    "point4 = slim.conv2d(point4,2,1)\n",
    "point4 = slim.conv2d(point4,2,1)\n",
    "point4 = slim.conv2d(point4,2,1)\n",
    "\n",
    "for l in tf.trainable_variables():\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "images = tf.random_normal(shape=[batch_size,image_size, image_size,3], \n",
    "                          dtype=tf.float32)\n",
    "point3 = slim.conv2d(images,2,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point3 = slim.conv2d(point3,2,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point3 = slim.conv2d(point3,2,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point3 = slim.conv2d(point3,2,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point3 = slim.conv2d(point3,2,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point3 = slim.conv2d(point3,2,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point3 = slim.conv2d(point3,2,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point3 = slim.conv2d(point3,2,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point3 = slim.conv2d(point3,2,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point3 = slim.conv2d(point3,2,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "\n",
    "point3 = slim.conv2d(point3,2,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point3 = slim.conv2d(point3,2,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point3 = slim.conv2d(point3,2,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point3 = slim.conv2d(point3,2,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point3 = slim.conv2d(point3,2,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point3 = slim.conv2d(point3,2,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point3 = slim.conv2d(point3,2,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point3 = slim.conv2d(point3,2,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point3 = slim.conv2d(point3,2,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "point3 = slim.conv2d(point3,2,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "\n",
    "for l in tf.trainable_variables():\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_time(l):\n",
    "    with tf.Session(config=config) as sess:\n",
    "\n",
    "        # Assert equality of the different methods\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        #norm, sep = sess.run([normal, separable])\n",
    "        #np.testing.assert_almost_equal(norm, sep, decimal=3)\n",
    "\n",
    "        repeats = 256\n",
    "\n",
    "        # Benchmark normal method\n",
    "        for layer in l :\n",
    "            start = time.time()\n",
    "            for _ in range(repeats):\n",
    "                _ = sess.run(layer)\n",
    "            end = time.time()\n",
    "            d1 = (end - start) / repeats * 100\n",
    "\n",
    "            # Print results\n",
    "            print(count(tf.get_default_graph() ,[layer.op.name]))\n",
    "            print(\"{}: {}ms \".format(layer,d1))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "from research.slim.nets.mobilenet import mobilenet_v2\n",
    "\n",
    "from tensorflow.contrib import slim\n",
    "import research.slim.nets.mobilenet.conv_blocks as ops\n",
    "from research.slim.nets.mobilenet import mobilenet as lib\n",
    "expand_input = ops.expand_input_by_factor\n",
    "from Analysis.count_flops import count \n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "from research.slim.nets.mobilenet import mobilenet_v2\n",
    "\n",
    "from tensorflow.contrib import slim\n",
    "import research.slim.nets.mobilenet.conv_blocks as ops\n",
    "from research.slim.nets.mobilenet import mobilenet as lib\n",
    "expand_input = ops.expand_input_by_factor\n",
    "from Analysis.count_flops import count \n",
    "import os \n",
    "\n",
    "# Define a scenario\n",
    "batch_size = 8\n",
    "channels = 32\n",
    "image_size = 32\n",
    "feature_maps = 64\n",
    "filter_size = 512\n",
    "depthwise_filters = 8\n",
    "tf.reset_default_graph()\n",
    "# Dummy images\n",
    "images = tf.random_normal(shape=[batch_size,image_size, image_size,3], \n",
    "                          dtype=tf.float32)\n",
    "normal = slim.conv2d(images,64,1,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "normal = slim.conv2d(normal,64,3,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "#normal = slim.conv2d(normal,1,1)\n",
    "\n",
    "\n",
    "# Separable method\n",
    "separable = ops.expanded_conv(images,2000,expansion_size= expand_input(6,divisible_by=1),residual=False)\n",
    "\n",
    "#separable = slim.conv2d(separable,1,1)\n",
    "\n",
    "\n",
    "\n",
    "config = tf.ConfigProto(device_count = {'GPU': 1})\n",
    "with tf.Session(config=config) as sess:\n",
    "\n",
    "    # Assert equality of the different methods\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    norm, sep = sess.run([normal, separable])\n",
    "    #np.testing.assert_almost_equal(norm, sep, decimal=3)\n",
    "\n",
    "    repeats = 256\n",
    "\n",
    "    # Benchmark normal method\n",
    "    start = time.time()\n",
    "    for _ in range(repeats):\n",
    "        _ = sess.run(normal)\n",
    "    end = time.time()\n",
    "    d1 = (end - start) / repeats * 100\n",
    "\n",
    "    # Benchmark seperable method\n",
    "    start = time.time()\n",
    "    for _ in range(repeats):\n",
    "        _ = sess.run(separable)\n",
    "    end = time.time()\n",
    "    d3 = (end - start) / repeats * 100\n",
    "\n",
    "    # Print results\n",
    "    print(count(tf.get_default_graph() ,[normal.op.name]))\n",
    "    print(count(tf.get_default_graph() ,[separable.op.name]))\n",
    "\n",
    "    print(\"Normal method: {}ms \\t Separable method: {}ms\".format(d1, d3))\n",
    "\n",
    "config = tf.ConfigProto(device_count = {'GPU': 0})\n",
    "with tf.Session(config=config) as sess:\n",
    "\n",
    "    # Assert equality of the different methods\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    norm, sep = sess.run([normal, separable])\n",
    "    #np.testing.assert_almost_equal(norm, sep, decimal=3)\n",
    "\n",
    "    repeats = 256\n",
    "\n",
    "    # Benchmark normal method\n",
    "    start = time.time()\n",
    "    for _ in range(repeats):\n",
    "        _ = sess.run(normal)\n",
    "    end = time.time()\n",
    "    d1 = (end - start) / repeats * 100\n",
    "\n",
    "    # Benchmark seperable method\n",
    "    start = time.time()\n",
    "    for _ in range(repeats):\n",
    "        _ = sess.run(separable)\n",
    "    end = time.time()\n",
    "    d3 = (end - start) / repeats * 100\n",
    "\n",
    "    # Print results\n",
    "    print(count(tf.get_default_graph() ,[normal.op.name]))\n",
    "    print(count(tf.get_default_graph() ,[separable.op.name]))\n",
    "\n",
    "    print(\"Normal method: {}ms \\t Separable method: {}ms\".format(d1, d3))\n",
    "    # gpu로 연산이 더 빠르지만 stadard conv는 더 많이 감소됨 \n",
    "    # cpu 연산할때는 irb가 더 빠름 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "channels = 32\n",
    "image_size = 64\n",
    "feature_maps = 64\n",
    "filter_size = 512\n",
    "irb_flops = image_size**2 * 3 * 6*(3 + 9 + 350)*batch_size\n",
    "conv_flops = image_size**2 * 9 * 3*256*batch_size\n",
    "irb_flops,conv_flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from research.slim.nets.mobilenet import mobilenet_v2\n",
    "\n",
    "from tensorflow.contrib import slim\n",
    "import research.slim.nets.mobilenet.conv_blocks as ops\n",
    "from research.slim.nets.mobilenet import mobilenet as lib\n",
    "expand_input = ops.expand_input_by_factor\n",
    "from Analysis.count_flops import count \n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "channels = 32\n",
    "image_size = 128\n",
    "feature_maps = 64\n",
    "filter_size = 15\n",
    "depthwise_filters = 8\n",
    "\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "    print('GPU found')\n",
    "else:\n",
    "    print(\"No GPU found\")\n",
    "config = tf.ConfigProto(device_count = {'GPU': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "images = tf.random_normal(shape=[batch_size,image_size, image_size,channels], \n",
    "                          dtype=tf.float32)\n",
    "x = slim.conv2d(images,64,3)\n",
    "x = slim.conv2d(x,256,3,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "x = slim.conv2d(x,256,3,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "x = slim.conv2d(x,256,3,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "x = slim.conv2d(x,256,3,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "x = slim.conv2d(x,256,3,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "x = slim.conv2d(x,1,1)\n",
    "\n",
    "\n",
    "with tf.Session(config=config) as sess : \n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(count(tf.get_default_graph() ,[x.op.name]))\n",
    "    t = time.time()\n",
    "    print(\"length:\",len(tf.all_variables()))\n",
    "\n",
    "    for i in range(10):\n",
    "        sess.run(x)\n",
    "    print (time.time()-t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "images = tf.random_normal(shape=[batch_size,image_size, image_size,channels], \n",
    "                          dtype=tf.float32)\n",
    "x = slim.conv2d(images,64,3)\n",
    "x = slim.conv2d(x,128,3,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "x = slim.conv2d(x,128,3,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "x = slim.conv2d(x,128,3,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "x = slim.conv2d(x,128,3,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "x = slim.conv2d(x,128,3,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "x = slim.conv2d(x,128,3,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "x = slim.conv2d(x,128,3,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "x = slim.conv2d(x,128,3,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "x = slim.conv2d(x,128,3,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "x = slim.conv2d(x,128,3,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "x = slim.conv2d(x,128,3,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "x = slim.conv2d(x,128,3,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "x = slim.conv2d(x,128,3,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "x = slim.conv2d(x,128,3,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "x = slim.conv2d(x,128,3,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "x = slim.conv2d(x,128,3,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "x = slim.conv2d(x,128,3,activation_fn=tf.nn.relu6,normalizer_fn=slim.batch_norm)\n",
    "\n",
    "x = slim.conv2d(x,1,1)\n",
    "\n",
    "\n",
    "with tf.Session(config=config) as sess : \n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(count(tf.get_default_graph() ,[x.op.name]))\n",
    "    t = time.time()\n",
    "    print(\"length:\",len(tf.all_variables()))\n",
    "\n",
    "    for i in range(10):\n",
    "        sess.run(x)\n",
    "    print (time.time()-t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "expand_kwargs = {\n",
    "        'expansion_size': expand_input(2),       \n",
    "        'split_expansion': 1,\n",
    "        'normalizer_fn': slim.batch_norm,\n",
    "        'residual': True\n",
    "        }\n",
    "\n",
    "images = tf.random_normal(shape=[batch_size,image_size, image_size,channels], \n",
    "                          dtype=tf.float32)\n",
    "with slim.arg_scope([ops.expanded_conv],**expand_kwargs):\n",
    "    x = ops.expanded_conv(images,64,expansion_size= expand_input(1,divisible_by=1))\n",
    "    x = ops.expanded_conv(x,256)\n",
    "    x = ops.expanded_conv(x,256)\n",
    "    x = ops.expanded_conv(x,400)\n",
    "    x = ops.expanded_conv(x,512)\n",
    "    x = ops.expanded_conv(x,512)\n",
    "\n",
    "\n",
    "    #x = ops.expanded_conv(x,160)\n",
    "\n",
    "\n",
    "    x = slim.conv2d(x,1,1)\n",
    "\n",
    "with  tf.Session(config=config) as sess : \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(count(tf.get_default_graph() ,[x.op.name]))\n",
    "    t = time.time()\n",
    "    print(\"length:\",len(tf.all_variables()))\n",
    "    for i in range(10):\n",
    "        sess.run(x)\n",
    "    print (time.time()-t)\n",
    "\n",
    "    #print(sess.run(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "expand_kwargs = {\n",
    "        'expansion_size': expand_input(6),       \n",
    "        'split_expansion': 1,\n",
    "        'normalizer_fn': slim.batch_norm,\n",
    "        'residual': True\n",
    "        }\n",
    "\n",
    "images = tf.random_normal(shape=[batch_size,image_size, image_size,channels], \n",
    "                          dtype=tf.float32)\n",
    "with slim.arg_scope([ops.expanded_conv],**expand_kwargs):\n",
    "    x = ops.expanded_conv(images,64,expansion_size= expand_input(6,divisible_by=1))\n",
    "    x = ops.expanded_conv(x,512)\n",
    "    x = ops.expanded_conv(x,256)\n",
    "    #x = ops.expanded_conv(x,1)\n",
    "    #x = ops.expanded_conv(x,1)\n",
    "    #x = ops.expanded_conv(x,1)\n",
    "    #x = ops.expanded_conv(x,1)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    #x = ops.expanded_conv(x,160)\n",
    "\n",
    "\n",
    "    x = slim.conv2d(x,1,1)\n",
    "\n",
    "with  tf.Session(config=config) as sess : \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(count(tf.get_default_graph() ,[x.op.name]))\n",
    "    t = time.time()\n",
    "    print(\"length:\",len(tf.all_variables()))\n",
    "    for i in range(10):\n",
    "        sess.run(x)\n",
    "    print (time.time()-t)\n",
    "\n",
    "    #print(sess.run(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "expand_kwargs = {\n",
    "        'expansion_size': expand_input(1),       \n",
    "        'split_expansion': 1,\n",
    "        'normalizer_fn': slim.batch_norm,\n",
    "        'residual': True\n",
    "        }\n",
    "\n",
    "images = tf.random_normal(shape=[batch_size,image_size, image_size,channels], \n",
    "                          dtype=tf.float32)\n",
    "with slim.arg_scope([ops.expanded_conv],**expand_kwargs):\n",
    "    x = ops.expanded_conv(images,64,expansion_size= expand_input(1,divisible_by=1))\n",
    "    x = ops.expanded_conv(x,512)\n",
    "    x = ops.expanded_conv(x,512)\n",
    "    x = ops.expanded_conv(x,512)\n",
    "    x = ops.expanded_conv(x,512)\n",
    "    x = ops.expanded_conv(x,512)\n",
    "    x = ops.expanded_conv(x,512)\n",
    "    x = ops.expanded_conv(x,512)\n",
    "    x = ops.expanded_conv(x,512)\n",
    "    x = ops.expanded_conv(x,512)\n",
    "    x = ops.expanded_conv(x,512)\n",
    "    #x = ops.expanded_conv(x,160)\n",
    "\n",
    "\n",
    "    x = slim.conv2d(x,1,1)\n",
    "\n",
    "with  tf.Session(config=config) as sess : \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(count(tf.get_default_graph() ,[x.op.name]))\n",
    "    t = time.time()\n",
    "    print(\"length:\",len(tf.all_variables()))\n",
    "    for i in range(10):\n",
    "        sess.run(x)\n",
    "    print (time.time()-t)\n",
    "\n",
    "    #print(sess.run(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "expand_kwargs = {\n",
    "        'expansion_size': expand_input(1),       \n",
    "        'split_expansion': 1,\n",
    "        'normalizer_fn': slim.batch_norm,\n",
    "        'residual': True\n",
    "        }\n",
    "\n",
    "images = tf.random_normal(shape=[batch_size,image_size, image_size,channels], \n",
    "                          dtype=tf.float32)\n",
    "with slim.arg_scope([ops.expanded_conv],**expand_kwargs):\n",
    "    x = ops.expanded_conv(images,64,expansion_size= expand_input(1,divisible_by=1))\n",
    "    x = ops.expanded_conv(x,1024)\n",
    "    x = ops.expanded_conv(x,1024)\n",
    "    x = ops.expanded_conv(x,768)\n",
    "    x = ops.expanded_conv(x,512)\n",
    "    x = ops.expanded_conv(x,512)\n",
    "\n",
    "    #x = ops.expanded_conv(x,160)\n",
    "\n",
    "\n",
    "    x = slim.conv2d(x,1,1)\n",
    "\n",
    "with  tf.Session(config=config) as sess : \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(count(tf.get_default_graph() ,[x.op.name]))\n",
    "    t = time.time()\n",
    "    print(\"length:\",len(tf.all_variables()))\n",
    "    for i in range(10):\n",
    "        sess.run(x)\n",
    "    print (time.time()-t)\n",
    "\n",
    "    #print(sess.run(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "expand_kwargs = {\n",
    "        'expansion_size': expand_input(1),       \n",
    "        'split_expansion': 1,\n",
    "        'normalizer_fn': slim.batch_norm,\n",
    "        'residual': True\n",
    "        }\n",
    "\n",
    "images = tf.random_normal(shape=[batch_size,image_size, image_size,channels], \n",
    "                          dtype=tf.float32)\n",
    "with slim.arg_scope([ops.expanded_conv],**expand_kwargs):\n",
    "    x = ops.expanded_conv(images,64,expansion_size= expand_input(1,divisible_by=1))\n",
    "    x = ops.expanded_conv(x,512)\n",
    "    x = ops.expanded_conv(x,512)\n",
    "    x = ops.expanded_conv(x,512)\n",
    "    x = ops.expanded_conv(x,512)\n",
    "    x = ops.expanded_conv(x,512)\n",
    "    x = ops.expanded_conv(x,512)\n",
    "    x = ops.expanded_conv(x,512)\n",
    "    x = ops.expanded_conv(x,512)\n",
    "    x = ops.expanded_conv(x,512)\n",
    "    x = ops.expanded_conv(x,512)\n",
    "    #x = ops.expanded_conv(x,160)\n",
    "\n",
    "\n",
    "    x = slim.conv2d(x,1,1)\n",
    "\n",
    "with  tf.Session(config=config) as sess : \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(count(tf.get_default_graph() ,[x.op.name]))\n",
    "    t = time.time()\n",
    "    print(\"length:\",len(tf.all_variables()))\n",
    "    for i in range(10):\n",
    "        sess.run(x)\n",
    "    print (time.time()-t)\n",
    "\n",
    "    #print(sess.run(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "expand_kwargs = {\n",
    "        'expansion_size': expand_input(6),       \n",
    "        'split_expansion': 1,\n",
    "        'normalizer_fn': slim.batch_norm,\n",
    "        'residual': True\n",
    "        }\n",
    "\n",
    "images = tf.random_normal(shape=[batch_size,image_size, image_size,channels], \n",
    "                          dtype=tf.float32)\n",
    "with slim.arg_scope([ops.expanded_conv],**expand_kwargs):\n",
    "    x = ops.expanded_conv(images,64,expansion_size= expand_input(1,divisible_by=1))\n",
    "    x = ops.expanded_conv(x,128)\n",
    "    x = ops.expanded_conv(x,128)\n",
    "    x = ops.expanded_conv(x,128)\n",
    "    x = ops.expanded_conv(x,128)\n",
    "    x = ops.expanded_conv(x,128)\n",
    "    x = ops.expanded_conv(x,128)\n",
    "    x = ops.expanded_conv(x,128)\n",
    "    x = ops.expanded_conv(x,128)\n",
    "    x = ops.expanded_conv(x,128)\n",
    "    x = ops.expanded_conv(x,128)\n",
    "    x = ops.expanded_conv(x,128)\n",
    "    x = ops.expanded_conv(x,128)\n",
    "    x = ops.expanded_conv(x,128)\n",
    "    # 13 \n",
    "\n",
    "\n",
    "\n",
    "    x = slim.conv2d(x,1,1)\n",
    "\n",
    "with  tf.Session(config=config) as sess : \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(count(tf.get_default_graph() ,[x.op.name]))\n",
    "    t = time.time()\n",
    "    print(\"length:\",len(tf.all_variables()))\n",
    "    for i in range(10):\n",
    "        sess.run(x)\n",
    "    print (time.time()-t)\n",
    "\n",
    "    #print(sess.run(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer가 많을수록 느리다. \n",
    "# 해상도가 작을때 irb가 빠르다.\n",
    "# 해상도가 작을때 cpu로 연산하면 irb 가 느리다. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
